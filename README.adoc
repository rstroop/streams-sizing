= Streams Monitoring

Automation to deploy the AMQ Streams Monitoring Demo.

== Tools available

* OpenShift User Workload Monitoring
* AMQ Streams Operator
* Grafana Operator

== Install The Demo Using Ansible

=== Parameters

To get these parameters log into OpenShift and select "Copy login command" from the top right dropdown menu of your username. After you are asked to log in one more time, you will be presented with your token and server name.

[options="header"]
|=======================
| Parameter | Example Value                                      | Definition
| token     | sha256~vFanQbthlPKfsaldJT3bdLXIyEkd7ypO_XPygY1DNtQ | access token for a user with cluster-admin privileges
| server    | https://api.mycluster.opentlc.com:6443             | OpenShift cluster API URL
|=======================


=== Deploying the demo

Provision an OpenShift 4.12 Workshop from demo.redhat.com

SSH into the Bastion host and clone this repository, then run the following commands

----
sudo yum install ansible
sudo pip3.9 install openshift
ansible-galaxy collection install kubernetes.core

token=REPLACE_ME
server=REPLACE_ME
----

change directory into the 'ansible' folder of the project before running the playbook

----
ansible-playbook -e token=${token} -e server=${server} playbook.yml
----

== Using the quarkus applications

To build the applications you first need to install Java and Maven

----
sudo yum install java-11-openjdk-devel

wget https://dlcdn.apache.org/maven/maven-3/3.9.1/binaries/apache-maven-3.9.1-bin.tar.gz
tar xvf apache-maven-3.9.1-bin.tar.gz
sudo mv apache-maven-3.9.1 /usr/local/apache-maven
export M2_HOME=/usr/local/apache-maven
export M2=$M2_HOME/bin 
export PATH=$M2:$PATH
----

It's a good idea to add the last three export lines to your ~/.bashrc file if you don't want to type them again when we create another SSH connection

Then to connect the applications from outside the OpenShift cluster you need to get the certificates for the TLS connections

----
PROJECT=kafka-cluster

oc extract -n $PROJECT secret/my-cluster-cluster-ca-cert --keys ca.crt --to /tmp/ --confirm
keytool -keystore /tmp/client-truststore.jks -alias CARoot -import -file /tmp/ca.crt -storepass kafka1 -noprompt
----

The keystore will be used by the applications to trust the broker in the connection.


=== Starting the Generator

In order for the broker to trust the generator we need to get the client cert as well

----
oc extract -n $PROJECT secret/generator --keys user.p12 --to /tmp/ --confirm
GENERATOR_PWD=$(oc get secret generator -n $PROJECT  -o jsonpath='{.data.user\.password}' | base64 -d )

keytool -importkeystore -srckeystore /tmp/user.p12 -srcstoretype pkcs12 -srcstorepass $GENERATOR_PWD -srcalias generator -destkeystore /tmp/generator-keystore.jks -deststoretype jks -deststorepass kafka1 -destalias generator
----

Now we tell the application where Kafka is and start it (make sure you are in the generator directory under the quarkus folder)

----
BOOTSTRAP_URL=$(oc get route my-cluster-kafka-bootstrap -n $PROJECT -o jsonpath='{.spec.host}'):443

mvn clean quarkus:dev -Dbootstrap.url=$BOOTSTRAP_URL  -Dgenerator.pwd=$GENERATOR_PWD
----

This will start quarkus in dev mode and host an web application on the bastion server. In order to access it on your machine we will use SSH port forwarding in another terminal

----
ssh -L 8080:localhost:8080 lab-user@bastion.[USE_YOUR_BASTION_HOST].opentlc.com
----

Now you will be able to go to a browser on your machine and visit localhost:8080 to see the application.

=== Starting the Transformer

We will start the transformer in the new  terminal we just opened to create the SSH tunnel

If you did not add the export commands to your ~/.bashrc file then you will need to run them again now

----
export M2_HOME=/usr/local/apache-maven
export M2=$M2_HOME/bin 
export PATH=$M2:$PATH
----

We already have the keystore for the broker, but we'll need to get the client cert for the transformer

----
PROJECT=kafka-cluster
oc extract -n $PROJECT secret/transformer --keys user.p12 --to /tmp/ --confirm
TRANSFORMER_PWD=$(oc get secret transformer -n $PROJECT  -o jsonpath='{.data.user\.password}' | base64 -d )

keytool -importkeystore -srckeystore /tmp/user.p12 -srcstoretype pkcs12 -srcstorepass $TRANSFORMER_PWD -srcalias transformer -destkeystore /tmp/transformer-keystore.jks -deststoretype jks -deststorepass kafka1 -destalias transformer
----

Now we tell the application where Kafka is and start it (make sure you are in the transformer directory under the quarkus folder)

----
BOOTSTRAP_URL=$(oc get route my-cluster-kafka-bootstrap -n $PROJECT -o jsonpath='{.spec.host}'):443

mvn clean quarkus:dev -Dbootstrap.url=$BOOTSTRAP_URL  -Dtransformer.pwd=$TRANSFORMER_PWD -Ddebug=5006
----

You can now go back to the app running on your local machine and you should see the EUR column updating.

== Running Performance Tests

If you'd like to run performance tests you will need to modify the cluster slightly. You can either modify the cluster on OpenShift or in the Ansible file, but you must remove the lines:

----
     authorization:
       type: simple
----

You can find the yaml file on OpenShift in the namespace kafka-cluster. Go to Installed Operators -> AMQ Streams -> Kafka -> my-cluster -> yaml and then remove those two lines. The cluster should restart itself once you save.

You could instead edit the file in this project under ansible/roles/streams/files/cluster.yaml and remove those two lines. Afterwards, you will have to run the playbook again and wait for it to take effect.

Once the cluster is updated you can navigate to the performance folder and run the test template using:

----
oc apply -f template.yaml
----

You can modify any of the fields in that template to suit your test. By default it will use the 3partitions-3replicas topic, but you can modify that as well from within the file. You'll see a few folders there from where I was running larger tests on larger numbers of brokers. Feel free to use any of those as well, but make sure you scale your brokers and create new topics so they are balanced for the tests. For most use cases, 3 brokers will be enough to test the results of different configurations on latency and cpu/memory usage. Make sure to allocate extra disks and enough disk space for the amount of data you plan to send. If the disks get full, they will break AMQ Streams and the PVs must be manually deleted to repair it. In most of my tests on AWS disks, I found that CPU usage was roughly equal to about 60MB/s per core per disk. This maxed out the IOPS which often caused massive fluctuations in performance. The brokers performed much better when I used 45MB/s per core per disk as my throughput. This allowed the brokers to withstand bursts, handle version mismatches, compress topics, and even tolerate a short term broker failure (such as an update) without breaking. Feel free to test your own configuration choices, but if you're looking for a good starting point or a great estimate I recommend going with Kafka brokers sized at 4 cores, at least 3 Disks, as much Memory as you want and then adding one broker for every 45MB/s (assuming your replica factor is 3 and you don't have less than 3 brokers).
